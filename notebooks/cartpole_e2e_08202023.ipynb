{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMxRg1LMJ8eXZIYSiZnY9EJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hululuzhu/mario-ai-2023/blob/main/notebooks/cartpole_e2e_08202023.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# An end-to-end colab to train CartPole AI from scratch and visualize the process\n",
        "- Contact: hululu.zhu@gmail.com\n",
        "- Last update: 08/20/2023\n",
        "- Note we used old versions of gym+SB3 for compabitility\n",
        "- Also note low-memory CPU instance (free tier) is good enough"
      ],
      "metadata": {
        "id": "KceOl67Yd1u2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "fV9ml6RMaP_y",
        "outputId": "615846cd-3f11-4db4-99bb-a3c7d2685a7d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------------------------------- \n",
            "Quiet install. ~5mins, be patient plz.\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# @title Run me to import necessary packages and set path\n",
        "print(\"-\" * 80, \"\\nQuiet install. ~5mins, be patient plz.\\n\" + \"-\" * 80)\n",
        "!git clone --quiet https://github.com/hululuzhu/mario-ai-2023.git > /dev/null\n",
        "!pip install -r mario-ai-2023/requirements.txt > /dev/null 2>&1\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import os, sys\n",
        "sys.path.append(os.path.abspath(\"/content/mario-ai-2023/lib\"))\n",
        "\n",
        "import gym\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "from IPython.display import Image as displayImage\n",
        "from stable_baselines3 import PPO\n",
        "\n",
        "def append_step_text(base_img, step, reward):\n",
        "  draw = ImageDraw.Draw(base_img)\n",
        "  font = ImageFont.truetype(r'/usr/share/fonts/truetype/liberation/LiberationMono-Regular.ttf', 40)\n",
        "  text = f'{step}  Reward: {reward}'\n",
        "  draw.text((5, 5), text, font = font, align =\"left\", fill=(0,0,0))\n",
        "  base_img.save('/tmp/001.png')\n",
        "  # ensure mutable\n",
        "  return Image.open(r'/tmp/001.png').copy()\n",
        "\n",
        "def eval_env(model, env, gif_path, is_human_view=True, sample_steps=100):\n",
        "    \"\"\"Take a glance of the world and save as gif.\"\"\"\n",
        "    images = []\n",
        "    obs = env.reset()\n",
        "    done = False\n",
        "    step, total_reward = 0, 0\n",
        "    for i in range(sample_steps):\n",
        "        screen = env.render('rgb_array')\n",
        "        if is_human_view:\n",
        "          # images.append(Image.fromarray(screen))\n",
        "          images.append(append_step_text(Image.fromarray(screen), step, total_reward))\n",
        "        else:\n",
        "          raise NotImplementedError\n",
        "        # for _ in range(4): # skip frames for efficiency\n",
        "        if done:\n",
        "            try:\n",
        "              # try multi-env within-session reset first\n",
        "              env.env.reset()\n",
        "            except:\n",
        "              env.reset()\n",
        "            break\n",
        "        # print(obs)\n",
        "        if model:\n",
        "          action, _ = model.predict(obs)\n",
        "        else:\n",
        "          action = env.action_space.sample()\n",
        "        # obs, reward, done, _, info = env.step(action)\n",
        "        obs, reward, done, info = env.step(action)\n",
        "        step += 1\n",
        "        total_reward += reward\n",
        "    if len(images) > 1:\n",
        "        # print(action)\n",
        "        # obs, reward, done, _, info = env.step(action)\n",
        "        obs, reward, done, info = env.step(action)\n",
        "        step += 1\n",
        "        total_reward += reward\n",
        "    if len(images) > 1:\n",
        "        images[0].save(\n",
        "            gif_path, save_all=True, append_images=images[1:], loop=0, duration=1)\n",
        "    else:\n",
        "        raise(\"Bad environment, cannot move\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Initialize the cartpole game\n",
        "env = gym.make('CartPole-v1')\n",
        "# Check out slides to see what the 4 outputs are, or check out\n",
        "# https://www.gymlibrary.dev/environments/classic_control/cart_pole/\n",
        "env.reset().tolist()"
      ],
      "metadata": {
        "id": "pI0KAoyoal9G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @Title, let's play the game by taking random actions!\n",
        "eval_env(model=None, env=env, gif_path='/tmp/eval01.gif')\n",
        "print('-' * 80, '\\n As you may expect, it does not last long\\n', '-' * 80)\n",
        "displayImage(open('/tmp/eval01.gif','rb').read())"
      ],
      "metadata": {
        "id": "wzBtYFxCa2XA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Let's Initialize a Game AI, using most advanced AI Algorithm called PPO\n",
        "# if you like to learn more about PPO, start with https://en.wikipedia.org/wiki/Proximal_Policy_Optimization\n",
        "my_ppo = PPO('MlpPolicy', env, tensorboard_log=\"cartpole\")"
      ],
      "metadata": {
        "id": "I8SicRlQa66X"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title We will use a tool called TensorBoard to track training progress\n",
        "%reload_ext tensorboard\n",
        "# Note the pattern of logdir, 'cartpole' matches to my_ppo definition,\n",
        "# 'ppo_mlp_1m_N' matches to learn code below\n",
        "%tensorboard --logdir cartpole/ppo_mlp_1m_1 --reload_multifile True"
      ],
      "metadata": {
        "id": "AMOUHBYgbAz0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Let's train the AI now, asking it to try to get \"higher scores\"!\n",
        "my_ppo.learn(total_timesteps=1000000, tb_log_name='ppo_mlp_1m')"
      ],
      "metadata": {
        "id": "XSnJ16KcbEox"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title After some training (or if you see tensorflow reports reasonably high scores), let's evaluate now!\n",
        "eval_env(my_ppo, env, '/tmp/eval02.gif')\n",
        "print('-' * 80, '\\n As you may expect, it now performs better!\\n', '-' * 80)\n",
        "displayImage(open('/tmp/eval02.gif','rb').read())"
      ],
      "metadata": {
        "id": "YJ4ETvQAbaIe"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Optionally, if you want to save the model and load\n",
        "# my_ppo.save('/tmp/your_path')\n",
        "# my_ppo = PPO.load('/tmp/your_path')"
      ],
      "metadata": {
        "id": "HPmkd3zZbhp6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}